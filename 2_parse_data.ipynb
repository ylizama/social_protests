{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ijson\n",
    "import json\n",
    "import csv\n",
    "import decimal\n",
    "import string\n",
    "\n",
    "def parse_tweets(infile, hdict, eco):\n",
    "    ht_dict = hdict[\"hashtags\"]\n",
    "    ht_id_counter = len(ht_dict) + 1\n",
    "    \n",
    "    url_dict = hdict[\"urls\"]\n",
    "    url_id_counter = len(url_dict) + 1\n",
    "    \n",
    "    user_dict = hdict[\"users\"]\n",
    "    tweet_dict = hdict[\"tweets\"]\n",
    "    edges_dict = hdict[\"edges\"]\n",
    "\n",
    "    f = open(infile)\n",
    "    # parse the tweet\n",
    "    tweets = ijson.items(f, \"item\")  \n",
    "    hasTweets = True\n",
    "    while(hasTweets):\n",
    "        try:\n",
    "            tweet = next(tweets)\n",
    "            created_at = tweet[\"created_at\"]  \n",
    "            try:\n",
    "                if tweet[\"truncated\"] == True and 'extended_tweet' in tweet and 'full_text' in tweet['extended_tweet']:\n",
    "                            text = tweet[\"extended_tweet\"]['full_text'].replace(\"\\\\\", \"\").replace(\"\\n\", \" \").replace(\"\\t\", \" \")\n",
    "                else:\n",
    "                    text = tweet[\"text\"].replace(\"\\\\\", \"\").replace(\"\\n\", \" \").replace(\"\\t\", \" \").replace(\"\\t\", \" \")\n",
    "            except KeyError:\n",
    "                continue                    \n",
    "            tid = str(tweet[\"id\"])\n",
    "\n",
    "            user_id = str(tweet[\"user\"][\"id\"])\n",
    "            screen_name = tweet[\"user\"][\"screen_name\"]\n",
    "            user_name = tweet[\"user\"][\"name\"]\n",
    "            user_dict[user_id] = [screen_name, user_name, eco]                  \n",
    "\n",
    "            lang = tweet[\"lang\"]\n",
    "            likes = tweet[\"favorite_count\"]\n",
    "\n",
    "            place = tweet[\"place\"]        \n",
    "            country_code = place[\"country_code\"] if place and \"country_code\" in place else \"\"\n",
    "            country = place[\"country\"] if place and \"country\" in place else \"\"\n",
    "            full_name = place[\"full_name\"] if place and \"full_name\" in place else \"\"\n",
    "            name = place[\"name\"] if place and \"name\" in place else \"\"\n",
    "            coordinates = place[\"bounding_box\"][\"coordinates\"] if place else \"\" \n",
    "\n",
    "            hashtags = tweet[\"entities\"][\"hashtags\"]\n",
    "            user_mentions = tweet[\"entities\"][\"user_mentions\"]\n",
    "            urls = tweet[\"entities\"][\"urls\"]\n",
    "            media = tweet[\"entities\"][\"media\"] if \"media\" in tweet[\"entities\"] else []\n",
    "\n",
    "            #reply tweets\n",
    "            tid_replies_to = tweet[\"in_reply_to_status_id\"]\n",
    "\n",
    "            #retweetes \n",
    "            rt_id = \"\"\n",
    "            rt_status = tweet.get(\"retweeted_status\", \"\")\n",
    "            if rt_status:\n",
    "                rt_created_at = rt_status[\"created_at\"] \n",
    "                rt_id = str(rt_status[\"id\"])            \n",
    "                rt_user_id = str(rt_status[\"user\"][\"id\"])\n",
    "                rt_text = rt_status[\"text\"].replace(\"\\\\\", \"\").replace(\"\\n\", \" \").replace(\"\\t\", \" \")\n",
    "\n",
    "                if rt_status[\"truncated\"] == True:\n",
    "                    if 'extended_tweet' in rt_status and 'full_text' in rt_status['extended_tweet']:\n",
    "                        rt_text = rt_status[\"extended_tweet\"]['full_text'].replace(\"\\\\\", \"\").replace(\"\\n\", \" \").replace(\"\\t\", \" \")\n",
    "\n",
    "                rt_lang = rt_status[\"lang\"]\n",
    "                rt_likes = rt_status[\"favorite_count\"]\n",
    "                rt_place = tweet[\"place\"]        \n",
    "                rt_country_code = rt_place[\"country_code\"] if rt_place and \"country_code\" in rt_place else \"\"\n",
    "                rt_country = rt_place[\"country\"] if rt_place and \"country\" in rt_place else \"\"\n",
    "                rt_full_name = rt_place[\"full_name\"] if rt_place and \"full_name\" in rt_place else \"\"\n",
    "                rt_name = rt_place[\"name\"] if rt_place and \"name\" in rt_place else \"\"\n",
    "                rt_coordinates = rt_place[\"bounding_box\"][\"coordinates\"] if rt_place else \"\"      \n",
    "\n",
    "                rt_row = [rt_id, rt_lang, rt_name, rt_text, rt_created_at, rt_full_name, rt_country, \n",
    "                          rt_country_code,rt_coordinates, rt_likes, \"tweet\", eco]\n",
    "\n",
    "                if  rt_id not in tweet_dict:\n",
    "                    tweet_dict[rt_id] = rt_row\n",
    "                    edges = [rt_user_id, rt_id, \"TWEETS\", eco]\n",
    "                    edges_dict['_'.join(edges)] = edges                       \n",
    "                elif tweet_dict[rt_id][3] == \"\":\n",
    "                    tweet_dict[rt_id] = rt_row\n",
    "\n",
    "                rt_user_screen_name = rt_status[\"user\"][\"screen_name\"]\n",
    "                rt_user_name = rt_status[\"user\"][\"name\"]\n",
    "                user_dict[rt_user_id] = rt_user_screen_name, rt_user_name, eco\n",
    "\n",
    "            #quoted tweets    \n",
    "            q_id = \"\"\n",
    "            q_status = tweet.get(\"quoted_status\", \"\")\n",
    "            if q_status:\n",
    "                q_created_at = q_status[\"created_at\"] \n",
    "            \n",
    "                q_id = str(q_status[\"id\"])\n",
    "                q_user_id = str(q_status[\"user\"][\"id\"])\n",
    "                q_text = q_status[\"text\"].replace(\"\\\\\", \"\").replace(\"\\n\", \" \").replace(\"\\t\", \" \")\n",
    "                if q_status[\"truncated\"] == True:\n",
    "                    if 'extended_tweet' in q_status and 'full_text' in q_status['extended_tweet']:\n",
    "                        q_text = q_status[\"extended_tweet\"]['full_text'].replace(\"\\\\\", \"\").replace(\"\\n\", \" \").replace(\"\\t\", \" \")\n",
    "\n",
    "\n",
    "                q_lang = q_status[\"lang\"]\n",
    "                q_likes = q_status[\"favorite_count\"]\n",
    "                q_place = q_status[\"place\"]               \n",
    "                q_country_code = q_place[\"country_code\"] if q_place and \"country_code\" in q_place else \"\"\n",
    "                q_country = q_place[\"country\"] if q_place and \"country\" in q_place else \"\"\n",
    "                q_full_name = q_place[\"full_name\"] if q_place and \"full_name\" in q_place else \"\"\n",
    "                q_name = q_place[\"name\"] if q_place and \"name\" in q_place else \"\"\n",
    "                q_coordinates = q_place[\"bounding_box\"][\"coordinates\"] if q_place else \"\"    \n",
    "\n",
    "                q_row = [q_id, q_lang, q_name, q_text, q_created_at, q_full_name, q_country, \n",
    "                          q_country_code, q_coordinates, q_likes, \"tweet\", eco]\n",
    "\n",
    "                if  q_id not in tweet_dict:\n",
    "                    tweet_dict[q_id] = q_row\n",
    "                    edges = [q_user_id, q_id, \"TWEETS\", eco]\n",
    "                    edges_dict['_'.join(edges)] = edges                     \n",
    "                elif tweet_dict[q_id][3] == \"\":\n",
    "                    tweet_dict[q_id] = q_row\n",
    "\n",
    "                q_user_screen_name = q_status[\"user\"][\"screen_name\"]\n",
    "                q_user_name = q_status[\"user\"][\"name\"]\n",
    "                user_dict[q_user_id] = q_user_screen_name, q_user_name, eco\n",
    "\n",
    "            row = [tid, lang, name, text, created_at, full_name, country, country_code, coordinates, likes, \"tweet\", eco]\n",
    "\n",
    "            if tid not in tweet_dict:\n",
    "                tweet_dict[tid] = row\n",
    "                edges = [user_id, tid, \"TWEETS\", eco]\n",
    "                edges_dict['_'.join(edges)] = edges\n",
    "            elif tweet_dict[tid][3] == \"\":\n",
    "                tweet_dict[tid] = row\n",
    "\n",
    "            # write out edges\n",
    "            if rt_id:\n",
    "                edges = [tid, rt_id, \"RETWEETS\", eco]\n",
    "                edges_dict['_'.join(edges)] = edges\n",
    "\n",
    "            if tid_replies_to:\n",
    "                tid_replies_to = str(tid_replies_to)\n",
    "\n",
    "                if tid_replies_to not in tweet_dict:\n",
    "                    tweet_dict[tid_replies_to] = [tid_replies_to, \"\", \"\", \"\", \"\", \"\",\"\",\"\",\"\",\"\", \"tweet\", eco]\n",
    "                edges = [tid, tid_replies_to, \"REPLIES_TO\", eco]\n",
    "                edges_dict['_'.join(edges)] = edges\n",
    "                id_user_replies  = tweet[\"in_reply_to_user_id_str\"]\n",
    "\n",
    "                if id_user_replies not in user_dict:\n",
    "                    screen_name_user_replies = tweet[\"in_reply_to_screen_name\"]\n",
    "                    user_dict[id_user_replies] = screen_name_user_replies, \"\", eco\n",
    "                edges = [id_user_replies, tid_replies_to, \"TWEETS\", eco]\n",
    "                edges_dict['_'.join(edges)] = edges\n",
    "\n",
    "            if q_id:\n",
    "                edges = [tid, q_id, \"QUOTED_TO\", eco]\n",
    "                edges_dict['_'.join(edges)] = edges\n",
    "\n",
    "\n",
    "            for hashtag in hashtags:\n",
    "                hashtag = hashtag[\"text\"].lower()\n",
    "                if hashtag not in ht_dict:\n",
    "                    ht_id = \"h{}\".format(ht_id_counter)\n",
    "                    ht_dict[hashtag] = [ht_id, eco]\n",
    "                    ht_id_counter += 1\n",
    "                else:\n",
    "                    ht_id = ht_dict[hashtag][0]\n",
    "                edges = [tid, ht_id, \"USES\", eco]\n",
    "                edges_dict['_'.join(edges)] = edges    \n",
    "\n",
    "            for url in urls:\n",
    "                url = url[\"expanded_url\"]\n",
    "                if url not in url_dict:\n",
    "                    url_id = \"u{}\".format(url_id_counter)\n",
    "                    url_dict[url] = [url_id, eco]\n",
    "                    url_id_counter += 1\n",
    "                else:\n",
    "                    url_id = url_dict[url][0] \n",
    "                edges = [tid, url_id, \"LINKS\", eco]\n",
    "                edges_dict['_'.join(edges)] = edges      \n",
    "\n",
    "            for m in media:\n",
    "                m = m[\"expanded_url\"]\n",
    "                if m not in url_dict:\n",
    "                    url_id = \"m{}\".format(url_id_counter)\n",
    "                    url_dict[m] = [url_id, eco]\n",
    "                    url_id_counter += 1\n",
    "                else:\n",
    "                    url_id = url_dict[m][0] \n",
    "                edges = [tid, url_id, \"LINKS\", eco]\n",
    "                edges_dict['_'.join(edges)] = edges     \n",
    "\n",
    "            for user_mention in user_mentions:\n",
    "                uid = str(user_mention[\"id\"])\n",
    "                mention_screen_name = user_mention[\"screen_name\"]\n",
    "                mention_user_name = user_mention[\"name\"]            \n",
    "                user_dict[uid] = mention_screen_name, mention_user_name, eco\n",
    "                edges = [tid, uid, \"MENTIONS\", eco]\n",
    "                edges_dict['_'.join(edges)] = edges  \n",
    "       \n",
    "        except StopIteration:\n",
    "            hasTweets = False\n",
    "        except: \n",
    "            continue\n",
    "    \n",
    "    hdict = {}\n",
    "    hdict['hashtags'] = ht_dict\n",
    "    hdict[\"users\"] = user_dict\n",
    "    hdict[\"urls\"] = url_dict\n",
    "    hdict[\"tweets\"] = tweet_dict\n",
    "    hdict[\"edges\"] = edges_dict\n",
    "    return hdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_csvs(file, hdict):\n",
    "\n",
    "    tweetfile = open(file + \"tweets.csv\", \"w\")\n",
    "    tweet_writer = csv.writer(tweetfile, delimiter='\\t')\n",
    "    \n",
    "    edgefile = open(file + \"edges.csv\", \"w\")\n",
    "    edge_writer = csv.writer(edgefile, delimiter='\\t')\n",
    "\n",
    "    tagfile = open(file + \"tags.csv\", \"w\")\n",
    "    tag_writer = csv.writer(tagfile, delimiter='\\t')\n",
    "    \n",
    "    urlfile = open(file + \"urls.csv\", \"w\")\n",
    "    url_writer = csv.writer(urlfile, delimiter='\\t')\n",
    "\n",
    "    userfile = open(file + \"users.csv\", \"w\")\n",
    "    user_writer = csv.writer(userfile, delimiter='\\t')\n",
    "    tweet_header = [\"tid:ID\", \"lang\", \"name\", \"text\", \"created_at\", \"full_name\",\n",
    "                        \"country\", \"country_code\", \"coordinates\", \"likes\", \":LABEL\", \"eco\"]\n",
    "    tweet_writer.writerow(tweet_header)    \n",
    "    \n",
    "    edge_header = [\":START_ID\", \":END_ID\", \":TYPE\", \"eco\"]\n",
    "    edge_writer.writerow(edge_header)\n",
    "\n",
    "    tag_header = [\"tagid:ID\", \"hashtag\", \":LABEL\", \"eco\"]\n",
    "    tag_writer.writerow(tag_header)\n",
    "    \n",
    "    url_header = [\"urlid:ID\", \"url\", \":LABEL\", \"eco\"]\n",
    "    url_writer.writerow(url_header)\n",
    "\n",
    "    user_header = [\"uid:ID\", \"screen_name\", \"name\", \":LABEL\", \"eco\"]\n",
    "    user_writer.writerow(user_header)\n",
    "    \n",
    "    validchars = string.ascii_letters + string.digits + ' ' + string.punctuation + \" _ÑñáéóíúÁÉÍÓÚ\"\n",
    "\n",
    "    for k, v in hdict[\"hashtags\"].items():\n",
    "        tag_writer.writerow([v[0], k, \"hashtag\", v[1]])      \n",
    "        \n",
    "    for k, v in hdict[\"urls\"].items():\n",
    "        url_writer.writerow([v[0], k, \"url\", v[1]])\n",
    "\n",
    "    for k, v in hdict[\"users\"].items():\n",
    "        try:\n",
    "            user_writer.writerow([k, v[0], v[1], \"user\", v[2]])      \n",
    "        except:\n",
    "            user1 = ''.join(c for c in v[0] if c in validchars)\n",
    "            user2 = ''.join(c for c in v[1] if c in validchars)\n",
    "            user_writer.writerow([k, user1, user2, \"user\", v[2]])  \n",
    "        \n",
    "    for v in hdict[\"tweets\"].values():\n",
    "        try:\n",
    "            tweet_writer.writerow(v)\n",
    "        except:\n",
    "            text = v[3] \n",
    "            twt = ''.join(c for c in text if c in validchars)\n",
    "            tweet_writer.writerow(twt)\n",
    "            \n",
    "    for v in hdict[\"edges\"].values():\n",
    "        edge_writer.writerow(v)\n",
    "        \n",
    "    tweetfile.close()\n",
    "    edgefile.close()\n",
    "    tagfile.close()\n",
    "    userfile.close()\n",
    "    urlfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdict = { \"hashtags\":{}, \"urls\":{}, \"users\":{}, \"tweets\":{}, \"edges\":{}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdict = parse_tweets('data/2018_black_lives_matter.json',  hdict, \"BLM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdict = parse_tweets('data/2018_me_too.json',  hdict, \"MT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdict = parse_tweets('data/2018_climate_change.json',  hdict, \"CCH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hdict = parse_tweets('data/2018_gun_control.json',  hdict, \"GC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1226015"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hdict[\"tweets\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdict3 = hdict.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_csvs('csvs/', hdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp csvs/* /usr/share/neo4j/import/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!/usr/share/neo4j/bin/neo4j-admin import --mode=csv --database=candidatos.db --nodes:tweet /usr/share/neo4j/import/tweets.csv --nodes:user /usr/share/neo4j/import/users.csv  --nodes:hashtag /usr/share/neo4j/import/tags.csv --nodes:url /usr/share/neo4j/import/urls.csv --relationships /usr/share/neo4j/import/edges.csv --id-type=string --delimiter='\\t'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo apt-get install --reinstall neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo service neo4j start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 rows affected.\n",
      "0 rows affected.\n",
      "0 rows affected.\n",
      "0 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%reload_ext cypher\n",
    "%cypher CREATE INDEX ON :user(uid)\n",
    "%cypher CREATE INDEX ON :url(urlid)\n",
    "%cypher CREATE INDEX ON :tweet(tid)\n",
    "%cypher CREATE INDEX ON :hashtag(hid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#etc/neo4j/conf/neo4j.conf\n",
    "#dbms.memory.heap.max_size=4096m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30458668\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "edges = []\n",
    "with open('data/csvs/edges.csv', 'r') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter='\\t')\n",
    "    for row in reader:\n",
    "        if row[2] == 'RETWEETS':\n",
    "            edges.append([row[1], row[0], row[2]])\n",
    "        else: \n",
    "            edges.append(row)\n",
    "            \n",
    "print(len(edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/csvs/edges2.csv', 'w') as f:\n",
    "    writer = csv.writer(f, delimiter='\\t')\n",
    "    writer.writerows(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30458668\n"
     ]
    }
   ],
   "source": [
    "print(len(edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
