{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext cypher\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot\n",
    "import datetime\n",
    "import string\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import ngrams\n",
    "import operator\n",
    "from itertools import islice\n",
    "from tabulate import tabulate\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweets(tweets):\n",
    "    patternUrl = re.compile('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
    "    patternUsers =  re.compile('@(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
    "    patternTags = re.compile('#(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
    "    allTweets = pd.Series(tweets).str.cat(sep='\\n|\\n||\\n')\n",
    "    allTweets = patternUrl.sub('', allTweets) #removing urls \n",
    "    allTweets = patternUsers.sub('', allTweets) #removing users\n",
    "    allTweets = patternTags.sub('', allTweets) #removing tags\n",
    "    return allTweets.split('\\n|\\n||\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words_ = set(stopwords.words('english'))  \n",
    "new_set = set(['000', 'de', 'rt', 'http', 'https', 'amp', '1', '25', 'pm', '2', '”', '—'])\n",
    "stop_words_ = stop_words_.union(new_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNGram(text, n, stop_words, m):\n",
    "    punct_signs = list(string.punctuation)\n",
    "    punct_signs.append('…')\n",
    "    punct_signs.append('¿')\n",
    "    for p in punct_signs:\n",
    "        text = text.replace(p, ' ')\n",
    "    clean_text = text.lower().split()\n",
    "    clean_text = [w for w in clean_text if w not in stop_words_]\n",
    "    total = len(clean_text)\n",
    "    h_dict = {}   \n",
    "    ngramas = ngrams(clean_text, n)\n",
    "    for grams in ngramas:\n",
    "        words = ' '.join(grams)        \n",
    "        words = words.strip() \n",
    "        if words in h_dict:\n",
    "            h_dict[words] = h_dict[words] + 1\n",
    "        else: \n",
    "            h_dict[words] = 1 \n",
    "    sorted_dict = sorted(h_dict.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    if m >=1:\n",
    "        results = list(islice(sorted_dict,  m))\n",
    "        results = [(v[0], v[1], v[1] * 100 / total) for v in results]\n",
    "        return results\n",
    "    else:\n",
    "        return list(islice(sorted_dict, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecos = [ 'BLM', 'MT', 'CCH', 'GC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61132 rows affected.\n",
      "26761 61132\n",
      "596858 rows affected.\n",
      "219013 596858\n",
      "40616 rows affected.\n",
      "20478 40616\n",
      "527675 rows affected.\n",
      "130193 527675\n"
     ]
    }
   ],
   "source": [
    "all_tweets_text = []\n",
    "for eco in ecos:\n",
    "    tweetsQ = %cypher match  (n:tweet)<-[r :TWEETS]-(n2:user) where n.eco = '{eco}'  return n.tid as tid, substring(n.text, 0, 10000000) as text, n.created_at as date\n",
    "    tweets = tweetsQ.get_dataframe().text.unique()\n",
    "    print(len(tweets), len(tweetsQ.get_dataframe().text))\n",
    "    text = cleanTweets(tweets, eco)\n",
    "    all_tweets_text.append(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unigrams, Bigrams, Trigrams in tweets by ecosystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BLM 33863\n",
      "\n",
      "MT 220872\n",
      "\n",
      "CCH 28672\n",
      "\n",
      "GC 61330\n"
     ]
    }
   ],
   "source": [
    "df_ngrams = []\n",
    "for idx, eco in enumerate(ecos):\n",
    "    print()\n",
    "    final = getNGram(all_tweets_text[idx], 1, stop_words_, -1)\n",
    "    final = final + getNGram(all_tweets_text[idx], 2, stop_words_, 100)\n",
    "    final = [(x[0], eco.lower(), x[1]) for x in final]\n",
    "    df = pd.DataFrame(final, columns=['Source', 'Target', 'Weight'])\n",
    "    df_ngrams.append(df)\n",
    "    print(eco, len(df))\n",
    "    df.to_csv(\"ngrams/\" + eco + \"_edges_ngrams.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ngrams = pd.concat(df_ngrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLM 10.55987360836311\n",
      "MT 13.565096526494983\n",
      "CCH 9.97802734375\n",
      "GC 28.09254850807109\n"
     ]
    }
   ],
   "source": [
    "for eco in ecos:\n",
    "    print(eco, df_ngrams[df_ngrams.Target==eco.lower()]['Weight'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering Tweets in English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52663 rows affected.\n",
      "22149 52663\n",
      "363557 rows affected.\n",
      "144056 363557\n",
      "37086 rows affected.\n",
      "18771 37086\n",
      "491128 rows affected.\n",
      "112213 491128\n"
     ]
    }
   ],
   "source": [
    "tweets_text = []\n",
    "for eco in ecos:\n",
    "    tweetsQ = %cypher match  (n:tweet)<-[r :TWEETS]-(n2:user) where n.eco = '{eco}' and n.lang = 'en' return n.tid as tid, substring(n.text, 0, 10000000) as text, n.created_at as date\n",
    "    tweets = tweetsQ.get_dataframe().text.unique()\n",
    "    print(len(tweets), len(tweetsQ.get_dataframe().text))\n",
    "    text = cleanTweets(tweets, eco)\n",
    "    tweets_text.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BLM 29434\n",
      "\n",
      "MT 84101\n",
      "\n",
      "CCH 24139\n",
      "\n",
      "GC 54621\n"
     ]
    }
   ],
   "source": [
    "df_ngrams = []\n",
    "for idx, eco in enumerate(ecos):\n",
    "    print()\n",
    "    final = getNGram(tweets_text[idx], 1, stop_words_, -1)\n",
    "    final = final + getNGram(tweets_text[idx], 2, stop_words_, 100)\n",
    "    final = [(x[0], eco.lower(), x[1]) for x in final]\n",
    "    df = pd.DataFrame(final, columns=['Source', 'Target', 'Weight'])\n",
    "    df_ngrams.append(df)\n",
    "    print(eco, len(df))\n",
    "    df.to_csv(\"ngrams/\" + eco + \"_en_edges_ngrams.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>n.eco</th>\n",
       "        <th>Tweets</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>CCH</td>\n",
       "        <td>40616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>GC</td>\n",
       "        <td>527641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>MT</td>\n",
       "        <td>596798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>BLM</td>\n",
       "        <td>60960</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[['CCH', 40616], ['GC', 527641], ['MT', 596798], ['BLM', 60960]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%cypher match  (n:tweet) return n.eco, count(n)  as  Tweets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
